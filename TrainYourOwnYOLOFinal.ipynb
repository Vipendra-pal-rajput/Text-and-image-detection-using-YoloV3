{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainYourOwnYOLOFinal.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jw7CocPKml1A",
        "outputId": "f37a6f46-664e-4280-c0c9-aa3151642a16"
      },
      "source": [
        "!git clone https://github.com/Vipendra-pal-rajput/Text-and-image-detection-using-YoloV3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Text-and-image-detection-using-YoloV3'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 455 (delta 13), reused 0 (delta 0), pack-reused 411\u001b[K\n",
            "Receiving objects: 100% (455/455), 80.14 MiB | 39.00 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY6tvIbMnH1x",
        "outputId": "48e9dd66-9c65-47a9-e40e-e7babf4eb82f"
      },
      "source": [
        "% cd Text-and-image-detection-using-YoloV3/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Text-and-image-detection-using-YoloV3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0Y1YBuZnLLm"
      },
      "source": [
        "! pip install -U -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edu14Imd2yad",
        "outputId": "4febe5d8-1d61-485d-acd9-ffc0eccbeb52"
      },
      "source": [
        "!dir"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1_Image_Annotation  CONTRIBUTING.md  Minimal_Example.py  TrainYourOwnYOLO.ipynb\n",
            "2_Training\t    Data\t     README.md\t\t Utils\n",
            "3_Inference\t    LICENSE\t     requirements.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJXED7PNqmpw"
      },
      "source": [
        "!rm -rf Data/Source_Images/Test_Image_Detection_Results\n",
        "!mkdir Data/Source_Images/Test_Image_Detection_Results\n",
        "!rm -rf Data/Source_Images/Test_Images\n",
        "!mkdir Data/Source_Images/Test_Images"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_joFoHGGpX3",
        "outputId": "024587e0-ae47-4388-cb24-1dd5f6cde111"
      },
      "source": [
        "% cd Data/Source_Images/Test_Images/"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EDuWbSrtGpq8",
        "outputId": "50ecde31-c1bd-4d8b-82e2-f55e0cfda4fc"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-824af87d-220c-4525-8429-8c792d1c8b02\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-824af87d-220c-4525-8429-8c792d1c8b02\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 1 (1).jpg to 1 (1).jpg\n",
            "Saving 1 (11).jpg to 1 (11).jpg\n",
            "Saving 1 (12).jpg to 1 (12).jpg\n",
            "Saving 1 (13).jpg to 1 (13).jpg\n",
            "Saving 1 (14).jpg to 1 (14).jpg\n",
            "Saving 1 (15).jpg to 1 (15).jpg\n",
            "Saving 1 (16).jpg to 1 (16).jpg\n",
            "Saving 1 (17).jpg to 1 (17).jpg\n",
            "Saving 1 (18).jpg to 1 (18).jpg\n",
            "Saving 1 (19).jpg to 1 (19).jpg\n",
            "Saving 1 (20).jpg to 1 (20).jpg\n",
            "Saving 1 (21).jpg to 1 (21).jpg\n",
            "Saving 1 (22).jpg to 1 (22).jpg\n",
            "Saving 1 (23).jpg to 1 (23).jpg\n",
            "Saving 1 (24).jpg to 1 (24).jpg\n",
            "Saving 1 (25).jpg to 1 (25).jpg\n",
            "Saving 1 (26).jpg to 1 (26).jpg\n",
            "Saving 1 (27).jpg to 1 (27).jpg\n",
            "Saving 1 (28).jpg to 1 (28).jpg\n",
            "Saving 1 (29).jpg to 1 (29).jpg\n",
            "Saving 1 (30).jpg to 1 (30).jpg\n",
            "Saving 1 (31).jpg to 1 (31).jpg\n",
            "Saving 1 (32).jpg to 1 (32).jpg\n",
            "Saving 1 (33).jpg to 1 (33).jpg\n",
            "Saving 1 (34).jpg to 1 (34).jpg\n",
            "Saving 1 (35).jpg to 1 (35).jpg\n",
            "Saving 1 (36).jpg to 1 (36).jpg\n",
            "Saving 1 (37).jpg to 1 (37).jpg\n",
            "Saving 1 (38).jpg to 1 (38).jpg\n",
            "Saving 1 (39).jpg to 1 (39).jpg\n",
            "Saving 1 (40).jpg to 1 (40).jpg\n",
            "Saving 1 (41).jpg to 1 (41).jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXL-ojDAIcWC",
        "outputId": "338968ea-bc75-411c-ffc3-ce2ae506e0b7"
      },
      "source": [
        "% cd ..\n",
        "% cd ..\n",
        "% cd .."
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images\n",
            "/content/Text-and-image-detection-using-YoloV3/Data\n",
            "/content/Text-and-image-detection-using-YoloV3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYGL7PQIIXQp",
        "outputId": "06ace90e-908e-44fa-bec5-62ed43803320"
      },
      "source": [
        "!dir"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1_Image_Annotation  CONTRIBUTING.md  Minimal_Example.py  TrainYourOwnYOLO.ipynb\n",
            "2_Training\t    Data\t     README.md\t\t Utils\n",
            "3_Inference\t    LICENSE\t     requirements.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZTI19q2EqT2",
        "outputId": "211e3029-9d50-4677-8fc6-02eab8c227e1"
      },
      "source": [
        "!python Minimal_Example.py"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detecting Cat Faces by calling: \n",
            "\n",
            " python /content/Text-and-image-detection-using-YoloV3/3_Inference/Detector.py --input_path /content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images --classes /content/Text-and-image-detection-using-YoloV3/Data/Model_Weights/data_classes.txt --output /content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Image_Detection_Results --yolo_model /content/Text-and-image-detection-using-YoloV3/Data/Model_Weights/trained_weights_final.h5 --box_file /content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Image_Detection_Results/Detection_Results.csv --anchors /content/Text-and-image-detection-using-YoloV3/2_Training/src/keras_yolo3/model_data/yolo_anchors.txt --file_types .jpg .jpeg .png  \n",
            "\n",
            "2021-04-02 10:36:55.574745: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-04-02 10:36:56.844555: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-02 10:36:56.881887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-02 10:36:56.882522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-04-02 10:36:56.882570: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-04-02 10:36:56.884575: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2021-04-02 10:36:56.887697: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-04-02 10:36:56.888068: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-04-02 10:36:56.890017: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-04-02 10:36:56.896778: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-04-02 10:36:56.902425: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-04-02 10:36:56.902556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-02 10:36:56.903209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-02 10:36:56.903763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2021-04-02 10:36:56.904222: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-04-02 10:36:56.911830: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199995000 Hz\n",
            "2021-04-02 10:36:56.912057: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559ea1624d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-04-02 10:36:56.912087: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-04-02 10:36:57.014667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-02 10:36:57.015415: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559ea1624f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-04-02 10:36:57.015459: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-04-02 10:36:57.015642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-02 10:36:57.016208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-04-02 10:36:57.016254: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-04-02 10:36:57.016303: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2021-04-02 10:36:57.016329: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-04-02 10:36:57.016368: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-04-02 10:36:57.016389: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-04-02 10:36:57.016413: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-04-02 10:36:57.016436: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-04-02 10:36:57.016508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-02 10:36:57.017074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-02 10:36:57.017649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2021-04-02 10:36:57.017705: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-04-02 10:36:57.523026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-02 10:36:57.523085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2021-04-02 10:36:57.523097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2021-04-02 10:36:57.523283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-02 10:36:57.523907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-02 10:36:57.524431: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-04-02 10:36:57.524483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13970 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Model_Weights/trained_weights_final.h5 model, anchors, and classes loaded in 6.47sec.\n",
            "Found 7 input labels: ['Stamp', 'Signature', 'Text_region', 'Picture_image', 'extra_dark', 'photo_image', 'QR code'] ...\n",
            "Found 32 input images: ['1 (30).jpg', '1 (17).jpg', '1 (27).jpg', '1 (37).jpg', '1 (40).jpg'] ...\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (30).jpg\n",
            "(416, 416, 3)\n",
            "2021-04-02 10:37:05.034109: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:581] layout failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2021-04-02 10:37:05.060804: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:581] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2021-04-02 10:37:05.232662: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:581] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
            "2021-04-02 10:37:05.373324: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-04-02 10:37:06.463511: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "Found 7 boxes for img\n",
            "extra_dark 0.66 (877, 0) (998, 1570)\n",
            "Signature 0.33 (224, 1234) (335, 1316)\n",
            "Signature 0.35 (388, 1250) (575, 1319)\n",
            "Signature 0.45 (679, 1174) (924, 1273)\n",
            "Stamp 0.42 (128, 196) (316, 380)\n",
            "Stamp 0.56 (161, 64) (281, 501)\n",
            "Stamp 0.93 (449, 739) (737, 943)\n",
            "Time spent: 2.769sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (17).jpg\n",
            "(416, 416, 3)\n",
            "Found 6 boxes for img\n",
            "Picture_image 0.99 (777, 339) (1591, 1389)\n",
            "Text_region 0.26 (834, 1304) (1496, 1468)\n",
            "Text_region 0.49 (127, 1911) (870, 2083)\n",
            "Text_region 0.59 (126, 292) (861, 469)\n",
            "Text_region 0.97 (75, 549) (905, 1704)\n",
            "Text_region 0.98 (937, 1626) (1521, 2007)\n",
            "Time spent: 0.120sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (27).jpg\n",
            "(416, 416, 3)\n",
            "Found 8 boxes for img\n",
            "Text_region 0.31 (143, 290) (823, 573)\n",
            "Text_region 0.84 (142, 182) (804, 872)\n",
            "Text_region 0.94 (141, 883) (773, 1450)\n",
            "Signature 0.31 (411, 1462) (511, 1522)\n",
            "Signature 0.49 (485, 1389) (743, 1466)\n",
            "Signature 0.65 (260, 1402) (416, 1454)\n",
            "Stamp 0.57 (61, 8) (229, 387)\n",
            "Stamp 0.69 (544, 37) (811, 252)\n",
            "Time spent: 0.095sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (37).jpg\n",
            "(416, 416, 3)\n",
            "Found 4 boxes for img\n",
            "extra_dark 0.39 (1262, 415) (1422, 1650)\n",
            "Picture_image 0.97 (98, 1194) (939, 1907)\n",
            "Text_region 0.72 (763, 468) (1282, 652)\n",
            "Text_region 0.88 (0, 233) (850, 954)\n",
            "Time spent: 0.102sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (40).jpg\n",
            "(416, 416, 3)\n",
            "Found 4 boxes for img\n",
            "extra_dark 0.57 (1330, 140) (1496, 2081)\n",
            "Text_region 0.66 (114, 603) (865, 1783)\n",
            "Text_region 0.76 (801, 342) (1437, 846)\n",
            "Text_region 0.81 (152, 234) (899, 640)\n",
            "Time spent: 0.103sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (25).jpg\n",
            "(416, 416, 3)\n",
            "Found 8 boxes for img\n",
            "Text_region 0.30 (325, 336) (842, 426)\n",
            "Text_region 0.92 (269, 404) (905, 643)\n",
            "Signature 0.36 (591, 645) (732, 699)\n",
            "Signature 0.59 (577, 711) (755, 811)\n",
            "Signature 0.60 (580, 627) (717, 740)\n",
            "Signature 0.69 (571, 920) (762, 975)\n",
            "Signature 0.95 (213, 1026) (329, 1095)\n",
            "Stamp 0.99 (532, 110) (800, 334)\n",
            "Time spent: 0.090sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (41).jpg\n",
            "(416, 416, 3)\n",
            "Found 3 boxes for img\n",
            "Picture_image 0.92 (722, 1278) (1499, 1664)\n",
            "Text_region 0.65 (92, 1192) (894, 1961)\n",
            "Text_region 0.66 (575, 1697) (1605, 1885)\n",
            "Time spent: 0.098sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (23).jpg\n",
            "(416, 416, 3)\n",
            "Found 8 boxes for img\n",
            "photo_image 0.44 (656, 651) (918, 839)\n",
            "photo_image 0.73 (148, 718) (432, 912)\n",
            "Signature 0.32 (246, 1268) (466, 1326)\n",
            "Signature 0.34 (524, 1317) (632, 1375)\n",
            "Signature 0.88 (631, 1210) (917, 1320)\n",
            "Stamp 0.60 (249, 846) (434, 1056)\n",
            "Stamp 0.80 (10, 91) (902, 530)\n",
            "Stamp 0.90 (644, 820) (875, 1054)\n",
            "Time spent: 0.089sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (18).jpg\n",
            "(416, 416, 3)\n",
            "Found 3 boxes for img\n",
            "Picture_image 0.98 (221, 1373) (1270, 1897)\n",
            "Text_region 0.42 (948, 1034) (1584, 1297)\n",
            "Text_region 0.95 (107, 174) (1021, 1024)\n",
            "Time spent: 0.112sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (36).jpg\n",
            "(416, 416, 3)\n",
            "Found 7 boxes for img\n",
            "extra_dark 0.35 (0, 40) (136, 2192)\n",
            "Text_region 0.27 (49, 1729) (823, 1894)\n",
            "Text_region 0.35 (82, 1303) (835, 1749)\n",
            "Text_region 0.67 (73, 386) (836, 553)\n",
            "Text_region 0.73 (141, 512) (783, 1862)\n",
            "Text_region 0.94 (771, 1018) (1367, 1193)\n",
            "Text_region 0.94 (813, 1423) (1350, 1619)\n",
            "Time spent: 0.156sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (33).jpg\n",
            "(416, 416, 3)\n",
            "Found 9 boxes for img\n",
            "Text_region 0.84 (284, 649) (889, 857)\n",
            "Text_region 0.89 (290, 1250) (872, 1345)\n",
            "Text_region 0.95 (252, 385) (935, 634)\n",
            "Text_region 0.97 (259, 922) (882, 1215)\n",
            "Signature 0.61 (227, 1392) (356, 1481)\n",
            "Signature 0.85 (381, 1397) (515, 1484)\n",
            "Signature 0.91 (732, 1428) (867, 1486)\n",
            "Stamp 0.79 (123, 269) (248, 503)\n",
            "Stamp 0.97 (655, 64) (870, 335)\n",
            "Time spent: 0.117sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (22).jpg\n",
            "(416, 416, 3)\n",
            "Found 6 boxes for img\n",
            "Text_region 0.93 (212, 1188) (897, 1351)\n",
            "Text_region 0.95 (215, 212) (887, 1132)\n",
            "Signature 0.83 (106, 940) (245, 1008)\n",
            "Signature 0.86 (157, 1353) (534, 1459)\n",
            "Signature 0.90 (600, 1363) (833, 1488)\n",
            "Stamp 0.82 (104, 115) (266, 412)\n",
            "Time spent: 0.103sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (19).jpg\n",
            "(416, 416, 3)\n",
            "Found 6 boxes for img\n",
            "Picture_image 1.00 (150, 1062) (1262, 1903)\n",
            "Text_region 0.30 (129, 1895) (1236, 2046)\n",
            "Text_region 0.38 (97, 303) (953, 420)\n",
            "Text_region 0.61 (798, 325) (1399, 913)\n",
            "Text_region 0.97 (1270, 618) (1539, 956)\n",
            "Text_region 0.99 (46, 475) (997, 977)\n",
            "Time spent: 0.141sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (26).jpg\n",
            "(416, 416, 3)\n",
            "Found 8 boxes for img\n",
            "Text_region 0.99 (246, 1022) (860, 1289)\n",
            "Signature 0.70 (135, 1148) (289, 1200)\n",
            "Signature 0.76 (250, 1278) (337, 1377)\n",
            "Signature 0.86 (729, 1321) (854, 1363)\n",
            "Signature 0.89 (404, 1270) (508, 1350)\n",
            "Stamp 0.26 (366, 569) (859, 824)\n",
            "Stamp 0.88 (142, 135) (893, 436)\n",
            "Stamp 0.96 (494, 591) (739, 805)\n",
            "Time spent: 0.113sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (24).jpg\n",
            "(416, 416, 3)\n",
            "Found 6 boxes for img\n",
            "Text_region 0.97 (186, 355) (906, 918)\n",
            "Text_region 0.98 (157, 965) (910, 1423)\n",
            "Signature 0.71 (34, 1123) (144, 1175)\n",
            "Signature 0.74 (246, 1409) (540, 1587)\n",
            "Stamp 0.38 (131, 147) (254, 273)\n",
            "Stamp 0.73 (415, 18) (706, 300)\n",
            "Time spent: 0.103sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (32).jpg\n",
            "(416, 416, 3)\n",
            "Found 8 boxes for img\n",
            "Text_region 0.95 (247, 766) (875, 1331)\n",
            "Text_region 0.98 (250, 414) (894, 736)\n",
            "Signature 0.34 (149, 1430) (296, 1551)\n",
            "Signature 0.88 (351, 1403) (453, 1508)\n",
            "Signature 0.91 (220, 1122) (331, 1188)\n",
            "Signature 0.93 (728, 1462) (876, 1524)\n",
            "Stamp 0.88 (148, 246) (276, 463)\n",
            "Stamp 0.98 (565, 115) (855, 343)\n",
            "Time spent: 0.116sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (20).jpg\n",
            "(416, 416, 3)\n",
            "Found 8 boxes for img\n",
            "photo_image 0.86 (378, 474) (588, 679)\n",
            "photo_image 0.90 (749, 558) (925, 758)\n",
            "Text_region 0.99 (246, 911) (959, 1180)\n",
            "Signature 0.83 (139, 1107) (221, 1194)\n",
            "Signature 0.83 (339, 1332) (703, 1440)\n",
            "Signature 0.87 (555, 1211) (784, 1325)\n",
            "Stamp 0.90 (73, 73) (1008, 390)\n",
            "Stamp 0.96 (488, 587) (779, 837)\n",
            "Time spent: 0.116sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (39).jpg\n",
            "(416, 416, 3)\n",
            "Found 5 boxes for img\n",
            "extra_dark 0.69 (1341, 149) (1475, 1919)\n",
            "Text_region 0.31 (770, 1152) (1395, 1350)\n",
            "Text_region 0.38 (761, 266) (1337, 1045)\n",
            "Text_region 0.80 (52, 281) (813, 1089)\n",
            "Text_region 0.94 (29, 1130) (956, 1907)\n",
            "Time spent: 0.136sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (14).jpg\n",
            "(416, 416, 3)\n",
            "Found 5 boxes for img\n",
            "Text_region 0.51 (159, 1406) (979, 1785)\n",
            "Text_region 0.65 (145, 1850) (990, 2068)\n",
            "Text_region 0.76 (115, 357) (1043, 1854)\n",
            "Text_region 0.97 (954, 327) (1635, 800)\n",
            "Text_region 0.99 (935, 1497) (1634, 2029)\n",
            "Time spent: 0.133sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (1).jpg\n",
            "(416, 416, 3)\n",
            "Found 6 boxes for img\n",
            "Picture_image 0.28 (732, 204) (1559, 453)\n",
            "Text_region 0.71 (656, 214) (1651, 499)\n",
            "Text_region 0.82 (125, 171) (694, 549)\n",
            "Text_region 0.87 (755, 503) (1551, 644)\n",
            "Text_region 0.94 (180, 667) (962, 1790)\n",
            "Text_region 0.99 (955, 1541) (1616, 1997)\n",
            "Time spent: 0.147sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (16).jpg\n",
            "(416, 416, 3)\n",
            "Found 5 boxes for img\n",
            "Picture_image 1.00 (147, 745) (1241, 1742)\n",
            "Text_region 0.47 (197, 1841) (1146, 1998)\n",
            "Text_region 0.64 (1001, 584) (1564, 748)\n",
            "Text_region 0.73 (164, 1650) (1201, 1858)\n",
            "Text_region 0.90 (160, 184) (983, 457)\n",
            "Time spent: 0.135sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (34).jpg\n",
            "(416, 416, 3)\n",
            "Found 2 boxes for img\n",
            "Text_region 0.28 (0, 0) (1087, 670)\n",
            "Signature 0.53 (667, 566) (987, 688)\n",
            "Time spent: 0.084sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (12).jpg\n",
            "(416, 416, 3)\n",
            "Found 5 boxes for img\n",
            "Picture_image 1.00 (806, 189) (1572, 1200)\n",
            "Text_region 0.62 (952, 1779) (1635, 2022)\n",
            "Text_region 0.64 (179, 1895) (938, 2053)\n",
            "Text_region 0.90 (773, 1235) (1608, 1500)\n",
            "Text_region 0.97 (178, 326) (941, 1789)\n",
            "Time spent: 0.136sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (35).jpg\n",
            "(416, 416, 3)\n",
            "Found 5 boxes for img\n",
            "extra_dark 0.58 (55, 30) (204, 2186)\n",
            "Picture_image 0.97 (186, 248) (965, 895)\n",
            "Text_region 0.48 (879, 1501) (1457, 1713)\n",
            "Text_region 0.72 (977, 1738) (1368, 1881)\n",
            "Text_region 0.86 (222, 900) (933, 1924)\n",
            "Time spent: 0.139sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (31).jpg\n",
            "(416, 416, 3)\n",
            "Found 11 boxes for img\n",
            "Text_region 0.93 (248, 155) (952, 620)\n",
            "Signature 0.30 (275, 1185) (801, 1323)\n",
            "Signature 0.34 (283, 903) (516, 1024)\n",
            "Signature 0.35 (723, 963) (937, 1041)\n",
            "Signature 0.48 (686, 691) (907, 756)\n",
            "Signature 0.56 (253, 698) (487, 755)\n",
            "Signature 0.59 (292, 723) (440, 776)\n",
            "Signature 0.61 (699, 712) (901, 789)\n",
            "Signature 0.63 (100, 942) (214, 1044)\n",
            "Stamp 0.26 (667, 14) (915, 198)\n",
            "Stamp 0.84 (164, 79) (261, 450)\n",
            "Time spent: 0.128sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (11).jpg\n",
            "(416, 416, 3)\n",
            "Found 5 boxes for img\n",
            "Text_region 0.25 (103, 364) (941, 755)\n",
            "Text_region 0.26 (234, 129) (724, 242)\n",
            "Text_region 0.36 (98, 1251) (913, 1952)\n",
            "Text_region 0.51 (107, 382) (984, 2136)\n",
            "Text_region 0.51 (903, 1727) (1541, 2026)\n",
            "Time spent: 0.134sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (38).jpg\n",
            "(416, 416, 3)\n",
            "Found 3 boxes for img\n",
            "Picture_image 0.88 (768, 278) (1496, 1033)\n",
            "Text_region 0.56 (0, 0) (716, 108)\n",
            "Text_region 0.69 (190, 244) (987, 2066)\n",
            "Time spent: 0.118sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (15).jpg\n",
            "(416, 416, 3)\n",
            "Found 4 boxes for img\n",
            "Text_region 0.83 (956, 270) (1524, 1039)\n",
            "Text_region 0.92 (964, 1227) (1493, 1449)\n",
            "Text_region 0.98 (92, 822) (941, 2055)\n",
            "Text_region 0.98 (38, 219) (954, 651)\n",
            "Time spent: 0.127sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (13).jpg\n",
            "(416, 416, 3)\n",
            "Found 5 boxes for img\n",
            "Picture_image 0.99 (166, 818) (862, 1378)\n",
            "Text_region 0.94 (53, 1451) (953, 1713)\n",
            "Text_region 0.95 (926, 214) (1558, 548)\n",
            "Text_region 0.97 (946, 873) (1537, 1642)\n",
            "Text_region 0.99 (41, 234) (945, 647)\n",
            "Time spent: 0.134sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (21).jpg\n",
            "(416, 416, 3)\n",
            "Found 3 boxes for img\n",
            "Text_region 0.42 (231, 294) (836, 596)\n",
            "Text_region 0.59 (0, 58) (1099, 793)\n",
            "Signature 0.65 (762, 694) (1064, 829)\n",
            "Time spent: 0.090sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (29).jpg\n",
            "(416, 416, 3)\n",
            "Found 7 boxes for img\n",
            "Text_region 0.92 (173, 193) (945, 402)\n",
            "Text_region 0.98 (202, 416) (930, 680)\n",
            "Text_region 0.99 (226, 659) (894, 1391)\n",
            "Signature 0.36 (840, 1429) (951, 1500)\n",
            "Signature 0.61 (522, 1324) (752, 1482)\n",
            "Signature 0.87 (108, 1034) (247, 1101)\n",
            "Stamp 0.80 (131, 48) (321, 268)\n",
            "Time spent: 0.109sec\n",
            "/content/Text-and-image-detection-using-YoloV3/Data/Source_Images/Test_Images/1 (28).jpg\n",
            "(416, 416, 3)\n",
            "Found 9 boxes for img\n",
            "photo_image 0.73 (202, 416) (409, 588)\n",
            "Text_region 0.97 (153, 775) (872, 1308)\n",
            "Signature 0.26 (739, 1454) (908, 1525)\n",
            "Signature 0.75 (249, 1340) (433, 1417)\n",
            "Signature 0.81 (735, 1408) (850, 1462)\n",
            "Signature 0.94 (532, 1301) (793, 1419)\n",
            "Stamp 0.56 (597, 254) (849, 405)\n",
            "Stamp 0.87 (27, 42) (310, 271)\n",
            "Stamp 0.90 (255, 190) (523, 458)\n",
            "Time spent: 0.116sec\n",
            "Processed 32 images in 10.2sec - 3.1FPS\n",
            "Detected Cat Faces in 20.6 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl7xDDGMqqHK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}